{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br1wlOej09d2"
      },
      "source": [
        "## Enviroment installing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXl9UfNVLaHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0df7cf-10bf-4d9d-de55-21e5208fbd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brags5NjLm5t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "features = ['load', 'ESMode1', 'ESMode2', 'ESMode3', 'ESMode4', 'ESMode5', 'ESMode6',\\\n",
        "            'RUType', 'Mode', 'Frequency', 'Bandwidth', 'Antennas', 'TXpower', 'year', 'month', 'day', 'hour']\n",
        "\n",
        "label = ['Energy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwC1VV0W1DXf"
      },
      "source": [
        "## Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBfdf6T8L-cl"
      },
      "outputs": [],
      "source": [
        "merge_data = pd.read_csv('/content/merge_minus_product.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLa_Zf4ww0xb"
      },
      "source": [
        "### Energy previous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6zVdo5VxAs-"
      },
      "outputs": [],
      "source": [
        "# Lagging value of energy\n",
        "\n",
        "def lagging_energy(df_data):\n",
        "    data_df = df_data.copy()\n",
        "    for lagging in range (1, 6):\n",
        "        col = 'energy_' + str(lagging)\n",
        "        data_df[col] = data_df.groupby(['bs', 'hour'])['energy'].shift(lagging)\n",
        "    return data_df\n",
        "\n",
        "# 1.7651"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33z1pL5jwDrx"
      },
      "source": [
        "### Energy statistical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtIMBzEJwCHi"
      },
      "outputs": [],
      "source": [
        "def energy_static(df_data):\n",
        "    data_df = df_data.copy()\n",
        "    data_df['mean_energy']  = data_df.groupby(['bs', 'hour'])['energy'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
        "    data_df['std_energy']   = data_df.groupby(['bs', 'hour'])['energy'].transform(lambda x: x.rolling(7, min_periods=1).std())\n",
        "    data_df['skew_energy']  = data_df.groupby(['bs', 'hour'])['energy'].transform(lambda x: x.rolling(7, min_periods=1).skew())\n",
        "    data_df['max_energy']   = data_df.groupby(['bs', 'hour'])['energy'].transform(lambda x: x.rolling(7, min_periods=1).max())\n",
        "    data_df['min_energy']   = data_df.groupby(['bs', 'hour'])['energy'].transform(lambda x: x.rolling(7, min_periods=1).min())\n",
        "    return data_df\n",
        "\n",
        "# 8.056"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNHMUsUy1GOo"
      },
      "source": [
        "### KPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aYw7ICT1Ly0"
      },
      "outputs": [],
      "source": [
        "def lagging_kpi(df_data):\n",
        "    data_df = df_data.copy()\n",
        "    kpis = ['load_cell0', 'load_cell1', 'load_cell2', 'load_cell3',\n",
        "            'frequency_cell0', 'frequency_cell1', 'frequency_cell2', 'frequency_cell3',\n",
        "            'bandwidth_cell0', 'bandwidth_cell1', 'bandwidth_cell2', 'bandwidth_cell3',\n",
        "            'antennas_cell0', 'antennas_cell1', 'antennas_cell2', 'antennas_cell3',\n",
        "            'txpower_cell0', 'txpower_cell1', 'txpower_cell2', 'txpower_cell3']\n",
        "    # print(kpis)\n",
        "    for kpi in kpis:\n",
        "        for lagging in range(1, 7):\n",
        "            col = kpi + '_' +str(lagging)\n",
        "            data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].shift(lagging)\n",
        "\n",
        "    return data_df\n",
        "\n",
        "\n",
        "# 1.845500987"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-0G1L0KbyOm"
      },
      "source": [
        "### KPI difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDx8advJb4Zt"
      },
      "outputs": [],
      "source": [
        "def kpi_difference(df_data):\n",
        "    data_df = df_data.copy()\n",
        "    kpis = ['load_cell0', 'load_cell1', 'load_cell2', 'load_cell3',\n",
        "            'frequency_cell0', 'frequency_cell1', 'frequency_cell2', 'frequency_cell3',\n",
        "            'bandwidth_cell0', 'bandwidth_cell1', 'bandwidth_cell2', 'bandwidth_cell3',\n",
        "            'antennas_cell0', 'antennas_cell1', 'antennas_cell2', 'antennas_cell3',\n",
        "            'txpower_cell0', 'txpower_cell1', 'txpower_cell2', 'txpower_cell3']\n",
        "    # print(kpis)\n",
        "    for kpi in kpis:\n",
        "        for lagging in range(1, 7):\n",
        "            col = kpi + '_diff_' + str(lagging)\n",
        "            data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].diff(lagging)\n",
        "    return data_df\n",
        "# 1.814460556"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEvIggMXeQpv"
      },
      "source": [
        "### KPI ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdJ-DVaneUs_"
      },
      "outputs": [],
      "source": [
        "def kpi_ratio(df_data):\n",
        "    data_df = df_data.copy()\n",
        "    kpis = ['load_cell0', 'load_cell1', 'load_cell2', 'load_cell3',\n",
        "            'frequency_cell0', 'frequency_cell1', 'frequency_cell2', 'frequency_cell3',\n",
        "            'bandwidth_cell0', 'bandwidth_cell1', 'bandwidth_cell2', 'bandwidth_cell3',\n",
        "            'antennas_cell0', 'antennas_cell1', 'antennas_cell2', 'antennas_cell3',\n",
        "            'txpower_cell0', 'txpower_cell1', 'txpower_cell2', 'txpower_cell3']\n",
        "    # print(kpis)\n",
        "    for kpi in kpis:\n",
        "        for lagging in range(1, 7):\n",
        "            col = kpi + '_ratio_' + str(lagging)\n",
        "            data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
        "    return data_df\n",
        "\n",
        "# 1.805322502"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-3cqA-34UWU"
      },
      "source": [
        "### KPI plus KPI ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjo-Mh-G4Y5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6f09e4-0696-4925-d8c0-b0b21bd7cda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n",
            "<ipython-input-10-c452486d3be3>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[col] = data_df.groupby(['bs', 'hour'])[kpi].pct_change(lagging)\n"
          ]
        }
      ],
      "source": [
        "KPI_merge_KPI_ratio   = kpi_ratio(merge_data)\n",
        "KPI_merge_KPI_lagging = lagging_energy(merge_data)\n",
        "KPI_merge_KPI_ratio   = KPI_merge_KPI_ratio.drop(columns = ['Unnamed: 0'])\n",
        "KPI_merge_KPI_lagging = KPI_merge_KPI_lagging.drop(columns = ['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAdqDsrM_0gi",
        "outputId": "20b0ae6d-0e5d-44af-8e94-839f966cd682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 118768 entries, 0 to 118767\n",
            "Columns: 145 entries, time to energy_5\n",
            "dtypes: float64(138), int64(4), object(3)\n",
            "memory usage: 131.4+ MB\n"
          ]
        }
      ],
      "source": [
        "KPI_merge_KPI_lagging.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5XpCNjY3Cxf"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfAU4Rya6EJW"
      },
      "outputs": [],
      "source": [
        "train_KPI_merge_KPI_ratio   = KPI_merge_KPI_ratio[KPI_merge_KPI_ratio['split'] == 'train']\n",
        "test_KPI_merge_KPI_ratio    = KPI_merge_KPI_ratio[KPI_merge_KPI_ratio['split'] == 'test']\n",
        "\n",
        "train_KPI_merge_KPI_lagging = KPI_merge_KPI_lagging[KPI_merge_KPI_lagging['split'] == 'train']\n",
        "test_KPI_merge_KPI_lagging = KPI_merge_KPI_lagging[KPI_merge_KPI_lagging['split'] == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T54bqwM0Hbi",
        "outputId": "0c0ddb00-77d7-44ed-d3c1-785270542897"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((92629, 260), (26139, 260), (92629, 145), (26139, 145))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_KPI_merge_KPI_ratio.shape, test_KPI_merge_KPI_ratio.shape, train_KPI_merge_KPI_lagging.shape, test_KPI_merge_KPI_lagging.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xM4no_Z05v-"
      },
      "source": [
        "### lgb1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XccTM8sa2H-d"
      },
      "outputs": [],
      "source": [
        "target_col = 'energy'\n",
        "drop_cols = ['time', 'bs', 'split', target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqdELyIt93sV"
      },
      "outputs": [],
      "source": [
        "def feature_enginning(train_df, valid_df, test_df):\n",
        "\n",
        "\n",
        "    train_df['split'] = 'train'\n",
        "    valid_df['split'] = 'valid'\n",
        "    test_df['split'] = 'test'\n",
        "\n",
        "    df = pd.concat([train_df, valid_df, test_df])\n",
        "    df['bs_en'] = df['bs'].apply(lambda x: int(x.strip('B_')))\n",
        "\n",
        "    df.sort_values(['time', 'bs'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "    train_df = df[df['split'] =='train']\n",
        "    valid_df = df[df['split'] =='valid']\n",
        "    test_df = df[df['split'] =='test']\n",
        "    residual_df = pd.concat([train_df, valid_df])\n",
        "\n",
        "    return train_df, valid_df, test_df, residual_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQW3yq9f2J8x",
        "outputId": "797b9f7f-14a9-4c83-ed8c-4bfbf7ecb3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9580\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 233\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.313705\n",
            "[100]\tvalid_0's mape: 0.0886033\n",
            "[200]\tvalid_0's mape: 0.0786587\n",
            "[300]\tvalid_0's mape: 0.0748199\n",
            "[400]\tvalid_0's mape: 0.07247\n",
            "[500]\tvalid_0's mape: 0.0713666\n",
            "[600]\tvalid_0's mape: 0.0701505\n",
            "[700]\tvalid_0's mape: 0.0689787\n",
            "[800]\tvalid_0's mape: 0.068123\n",
            "[900]\tvalid_0's mape: 0.0677855\n",
            "[1000]\tvalid_0's mape: 0.0672397\n",
            "[1100]\tvalid_0's mape: 0.0670226\n",
            "[1200]\tvalid_0's mape: 0.0665261\n",
            "[1300]\tvalid_0's mape: 0.0662287\n",
            "[1400]\tvalid_0's mape: 0.0660455\n",
            "[1500]\tvalid_0's mape: 0.0658188\n",
            "[1600]\tvalid_0's mape: 0.0656552\n",
            "[1700]\tvalid_0's mape: 0.0655166\n",
            "[1800]\tvalid_0's mape: 0.0655005\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 0\n",
            "Valid score :  0.06566904078054535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059413 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8982\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 167\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.276547\n",
            "[100]\tvalid_0's mape: 0.0803641\n",
            "[200]\tvalid_0's mape: 0.0705342\n",
            "[300]\tvalid_0's mape: 0.0670177\n",
            "[400]\tvalid_0's mape: 0.0650252\n",
            "[500]\tvalid_0's mape: 0.0635966\n",
            "[600]\tvalid_0's mape: 0.0619817\n",
            "[700]\tvalid_0's mape: 0.0612013\n",
            "[800]\tvalid_0's mape: 0.0605081\n",
            "[900]\tvalid_0's mape: 0.0599513\n",
            "[1000]\tvalid_0's mape: 0.0596689\n",
            "[1100]\tvalid_0's mape: 0.0594225\n",
            "[1200]\tvalid_0's mape: 0.0592123\n",
            "[1300]\tvalid_0's mape: 0.0590141\n",
            "[1400]\tvalid_0's mape: 0.0587957\n",
            "[1500]\tvalid_0's mape: 0.058594\n",
            "[1600]\tvalid_0's mape: 0.0582502\n",
            "[1700]\tvalid_0's mape: 0.0580547\n",
            "[1800]\tvalid_0's mape: 0.0578402\n",
            "[1900]\tvalid_0's mape: 0.0577159\n",
            "[2000]\tvalid_0's mape: 0.0576711\n",
            "[2100]\tvalid_0's mape: 0.0575928\n",
            "[2200]\tvalid_0's mape: 0.0574375\n",
            "[2300]\tvalid_0's mape: 0.0573805\n",
            "[2400]\tvalid_0's mape: 0.0573296\n",
            "[2500]\tvalid_0's mape: 0.0572283\n",
            "[2600]\tvalid_0's mape: 0.0571712\n",
            "[2700]\tvalid_0's mape: 0.0570352\n",
            "[2800]\tvalid_0's mape: 0.0570366\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 1\n",
            "Valid score :  0.05698364203822102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9661\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 233\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.059540\n",
            "[100]\tvalid_0's mape: 0.0747463\n",
            "[200]\tvalid_0's mape: 0.0649777\n",
            "[300]\tvalid_0's mape: 0.0620475\n",
            "[400]\tvalid_0's mape: 0.0596299\n",
            "[500]\tvalid_0's mape: 0.0583992\n",
            "[600]\tvalid_0's mape: 0.0574348\n",
            "[700]\tvalid_0's mape: 0.0568652\n",
            "[800]\tvalid_0's mape: 0.056212\n",
            "[900]\tvalid_0's mape: 0.0557403\n",
            "[1000]\tvalid_0's mape: 0.0554625\n",
            "[1100]\tvalid_0's mape: 0.0549844\n",
            "[1200]\tvalid_0's mape: 0.0547074\n",
            "[1300]\tvalid_0's mape: 0.0543828\n",
            "[1400]\tvalid_0's mape: 0.0541633\n",
            "[1500]\tvalid_0's mape: 0.0540583\n",
            "[1600]\tvalid_0's mape: 0.0538783\n",
            "[1700]\tvalid_0's mape: 0.0538019\n",
            "[1800]\tvalid_0's mape: 0.0536611\n",
            "[1900]\tvalid_0's mape: 0.0535912\n",
            "[2000]\tvalid_0's mape: 0.0535088\n",
            "[2100]\tvalid_0's mape: 0.0534694\n",
            "[2200]\tvalid_0's mape: 0.0534588\n",
            "[2300]\tvalid_0's mape: 0.0533762\n",
            "[2400]\tvalid_0's mape: 0.0532647\n",
            "[2500]\tvalid_0's mape: 0.0532676\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 2\n",
            "Valid score :  0.05323407153649868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086815 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9514\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 233\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 27.913267\n",
            "[100]\tvalid_0's mape: 0.0725883\n",
            "[200]\tvalid_0's mape: 0.0628179\n",
            "[300]\tvalid_0's mape: 0.0591209\n",
            "[400]\tvalid_0's mape: 0.0566503\n",
            "[500]\tvalid_0's mape: 0.0549494\n",
            "[600]\tvalid_0's mape: 0.0537115\n",
            "[700]\tvalid_0's mape: 0.0531467\n",
            "[800]\tvalid_0's mape: 0.0527181\n",
            "[900]\tvalid_0's mape: 0.0520587\n",
            "[1000]\tvalid_0's mape: 0.0517055\n",
            "[1100]\tvalid_0's mape: 0.0515081\n",
            "[1200]\tvalid_0's mape: 0.0512941\n",
            "[1300]\tvalid_0's mape: 0.0512014\n",
            "[1400]\tvalid_0's mape: 0.0510281\n",
            "[1500]\tvalid_0's mape: 0.0510006\n",
            "[1600]\tvalid_0's mape: 0.0508337\n",
            "[1700]\tvalid_0's mape: 0.0506462\n",
            "[1800]\tvalid_0's mape: 0.050577\n",
            "[1900]\tvalid_0's mape: 0.0504658\n",
            "[2000]\tvalid_0's mape: 0.0504416\n",
            "[2100]\tvalid_0's mape: 0.050375\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 3\n",
            "Valid score :  0.05037091623365217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083416 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8710\n",
            "[LightGBM] [Info] Number of data points in the train set: 74104, number of used features: 202\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.131925\n",
            "[100]\tvalid_0's mape: 0.0793559\n",
            "[200]\tvalid_0's mape: 0.0694022\n",
            "[300]\tvalid_0's mape: 0.0643951\n",
            "[400]\tvalid_0's mape: 0.0624707\n",
            "[500]\tvalid_0's mape: 0.0613253\n",
            "[600]\tvalid_0's mape: 0.0601656\n",
            "[700]\tvalid_0's mape: 0.0594321\n",
            "[800]\tvalid_0's mape: 0.0586556\n",
            "[900]\tvalid_0's mape: 0.0582776\n",
            "[1000]\tvalid_0's mape: 0.0579984\n",
            "[1100]\tvalid_0's mape: 0.0576382\n",
            "[1200]\tvalid_0's mape: 0.0572484\n",
            "[1300]\tvalid_0's mape: 0.0569698\n",
            "[1400]\tvalid_0's mape: 0.0568256\n",
            "[1500]\tvalid_0's mape: 0.0566811\n",
            "[1600]\tvalid_0's mape: 0.0565856\n",
            "[1700]\tvalid_0's mape: 0.0565048\n",
            "[1800]\tvalid_0's mape: 0.0564088\n",
            "[1900]\tvalid_0's mape: 0.056371\n",
            "[2000]\tvalid_0's mape: 0.0563291\n",
            "[2100]\tvalid_0's mape: 0.0563302\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 4\n",
            "Valid score :  0.05628749638955734\n",
            "_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*\n",
            "OOF score :  0.05650903578735418\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "kf = model_selection.KFold(n_splits=5)\n",
        "kf = kf.split(X=train_KPI_merge_KPI_ratio)\n",
        "\n",
        "oof_valid_preds = np.zeros(train_KPI_merge_KPI_ratio.shape[0], )\n",
        "test_preds_list = []\n",
        "residual_list   = []\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(kf):\n",
        "\n",
        "    train_df = train_KPI_merge_KPI_ratio.iloc[train_idx]\n",
        "    valid_df = train_KPI_merge_KPI_ratio.iloc[valid_idx]\n",
        "    test_df = test_KPI_merge_KPI_ratio.copy()\n",
        "\n",
        "    train_df, valid_df, test_df, residual_df = feature_enginning(train_df=train_df, valid_df=valid_df, test_df=test_df)\n",
        "    train_cols = [col for col in train_df.columns if col not in drop_cols]\n",
        "\n",
        "    X_train, y_train        = train_df[train_cols], train_df[target_col]\n",
        "    X_valid, y_valid        = valid_df[train_cols], valid_df[target_col]\n",
        "    X_test                  = test_df[train_cols]\n",
        "    X_residual, y_residual  = residual_df[train_cols], residual_df[target_col]\n",
        "\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'boosting_type': 'gbdt',\n",
        "        # 'learning_rate': 0.01,\n",
        "        'n_jobs': -1,\n",
        "        'max_depth' : -1,\n",
        "        # 'reg_alpha': 0.3,\n",
        "        # 'reg_lambda': 0.3,\n",
        "        'metric': 'mape',\n",
        "        'num_boost_round': 10000,\n",
        "    }\n",
        "\n",
        "    # model = lgb.LGBMRegressor(**lgb_study.best_params)\n",
        "    model1 = lgb.LGBMRegressor(**params)\n",
        "    # model = lgb.LGBMRegressor()\n",
        "\n",
        "    early_stopping_callback = lgb.early_stopping(100, first_metric_only=True, verbose=False)\n",
        "    verbose_callback = lgb.log_evaluation(100)\n",
        "\n",
        "    model1.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        callbacks=[early_stopping_callback, verbose_callback],\n",
        "    )\n",
        "\n",
        "    valid_preds = model1.predict(X_valid)\n",
        "    test_preds = model1.predict(X_test)\n",
        "    residual_preds = model1.predict(X_residual)\n",
        "\n",
        "\n",
        "    val_score = metrics.mean_absolute_percentage_error(y_valid, valid_preds)\n",
        "    oof_valid_preds[valid_idx] = valid_preds\n",
        "    test_preds_list.append(test_preds)\n",
        "    residual_list.append(residual_preds)\n",
        "\n",
        "    print(\"=*\"*50)\n",
        "    print(f\"Fold : {i}\")\n",
        "    print(f\"Valid score : \", val_score)\n",
        "\n",
        "oof_score = metrics.mean_absolute_percentage_error(train_KPI_merge_KPI_ratio[target_col], oof_valid_preds)\n",
        "print(\"_-*\"*50)\n",
        "print(f\"OOF score : \", oof_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNUVAiGj4Ugs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "test_preds_mean = np.mean(test_preds_list, axis=0).tolist()\n",
        "residual_mean   = np.mean(residual_list, axis=0).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W78r_6GC50l",
        "outputId": "2af05d41-94cf-414d-bbad-2d30a5848ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-81cf83925873>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_KPI_merge_KPI_lagging['residual'] = residual_mean\n",
            "<ipython-input-19-81cf83925873>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_KPI_merge_KPI_lagging['residual'] = test_preds_mean\n"
          ]
        }
      ],
      "source": [
        "train_KPI_merge_KPI_lagging['residual'] = residual_mean\n",
        "test_KPI_merge_KPI_lagging['residual'] = test_preds_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "5HWmTr9eFnEA",
        "outputId": "5847a514-e34a-49c1-f5ca-4d80b807ce00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 92629 entries, 0 to 118767\n",
            "Columns: 146 entries, time to residual\n",
            "dtypes: float64(139), int64(4), object(3)\n",
            "memory usage: 103.9+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time   bs  load_cell0  load_cell1  load_cell2  load_cell3  \\\n",
              "0  2023-01-01 01:00:00  B_0    0.487936         NaN         NaN         NaN   \n",
              "1  2023-01-01 01:00:00  B_1    0.034770         NaN         NaN         NaN   \n",
              "\n",
              "   esmode1_cell0  esmode1_cell1  esmode1_cell2  esmode1_cell3  ...  day  hour  \\\n",
              "0            0.0            NaN            NaN            NaN  ...    1     1   \n",
              "1            0.0            NaN            NaN            NaN  ...    1     1   \n",
              "\n",
              "      energy  split  energy_1  energy_2  energy_3  energy_4  energy_5  \\\n",
              "0  64.275037  train       NaN       NaN       NaN       NaN       NaN   \n",
              "1  18.086697  train       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "    residual  \n",
              "0  58.590689  \n",
              "1  19.379589  \n",
              "\n",
              "[2 rows x 146 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6300ee4b-216e-4e6c-b14b-cc939173716b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>bs</th>\n",
              "      <th>load_cell0</th>\n",
              "      <th>load_cell1</th>\n",
              "      <th>load_cell2</th>\n",
              "      <th>load_cell3</th>\n",
              "      <th>esmode1_cell0</th>\n",
              "      <th>esmode1_cell1</th>\n",
              "      <th>esmode1_cell2</th>\n",
              "      <th>esmode1_cell3</th>\n",
              "      <th>...</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>energy</th>\n",
              "      <th>split</th>\n",
              "      <th>energy_1</th>\n",
              "      <th>energy_2</th>\n",
              "      <th>energy_3</th>\n",
              "      <th>energy_4</th>\n",
              "      <th>energy_5</th>\n",
              "      <th>residual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-01 01:00:00</td>\n",
              "      <td>B_0</td>\n",
              "      <td>0.487936</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>64.275037</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58.590689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-01 01:00:00</td>\n",
              "      <td>B_1</td>\n",
              "      <td>0.034770</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18.086697</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.379589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 146 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6300ee4b-216e-4e6c-b14b-cc939173716b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6300ee4b-216e-4e6c-b14b-cc939173716b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6300ee4b-216e-4e6c-b14b-cc939173716b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ffd743e-f01e-4474-ab97-2635d10f87a6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ffd743e-f01e-4474-ab97-2635d10f87a6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ffd743e-f01e-4474-ab97-2635d10f87a6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_KPI_merge_KPI_lagging.info()\n",
        "train_KPI_merge_KPI_lagging.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8DIMFkEF3KK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8f81dc-20b2-48eb-82ba-26ad6d135ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8307\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 139\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.313705\n",
            "[100]\tvalid_0's mape: 0.111331\n",
            "[200]\tvalid_0's mape: 0.104155\n",
            "[300]\tvalid_0's mape: 0.0988641\n",
            "[400]\tvalid_0's mape: 0.0953309\n",
            "[500]\tvalid_0's mape: 0.0908592\n",
            "[600]\tvalid_0's mape: 0.089683\n",
            "[700]\tvalid_0's mape: 0.0879213\n",
            "[800]\tvalid_0's mape: 0.0861236\n",
            "[900]\tvalid_0's mape: 0.0854619\n",
            "[1000]\tvalid_0's mape: 0.0849169\n",
            "[1100]\tvalid_0's mape: 0.0841255\n",
            "[1200]\tvalid_0's mape: 0.0837664\n",
            "[1300]\tvalid_0's mape: 0.0829643\n",
            "[1400]\tvalid_0's mape: 0.0827333\n",
            "[1500]\tvalid_0's mape: 0.0823061\n",
            "[1600]\tvalid_0's mape: 0.0821258\n",
            "[1700]\tvalid_0's mape: 0.0817946\n",
            "[1800]\tvalid_0's mape: 0.0815206\n",
            "[1900]\tvalid_0's mape: 0.0812605\n",
            "[2000]\tvalid_0's mape: 0.0811381\n",
            "[2100]\tvalid_0's mape: 0.0809831\n",
            "[2200]\tvalid_0's mape: 0.0809322\n",
            "[2300]\tvalid_0's mape: 0.0806485\n",
            "[2400]\tvalid_0's mape: 0.0803781\n",
            "[2500]\tvalid_0's mape: 0.0802517\n",
            "[2600]\tvalid_0's mape: 0.0801246\n",
            "[2700]\tvalid_0's mape: 0.0799458\n",
            "[2800]\tvalid_0's mape: 0.0798002\n",
            "[2900]\tvalid_0's mape: 0.0797087\n",
            "[3000]\tvalid_0's mape: 0.0796096\n",
            "[3100]\tvalid_0's mape: 0.0795392\n",
            "[3200]\tvalid_0's mape: 0.0793685\n",
            "[3300]\tvalid_0's mape: 0.0793259\n",
            "[3400]\tvalid_0's mape: 0.0792736\n",
            "[3500]\tvalid_0's mape: 0.0791565\n",
            "[3600]\tvalid_0's mape: 0.0791149\n",
            "[3700]\tvalid_0's mape: 0.0790362\n",
            "[3800]\tvalid_0's mape: 0.0790123\n",
            "[3900]\tvalid_0's mape: 0.0789577\n",
            "[4000]\tvalid_0's mape: 0.0788479\n",
            "[4100]\tvalid_0's mape: 0.0787487\n",
            "[4200]\tvalid_0's mape: 0.0787158\n",
            "[4300]\tvalid_0's mape: 0.0785874\n",
            "[4400]\tvalid_0's mape: 0.0785182\n",
            "[4500]\tvalid_0's mape: 0.0784218\n",
            "[4600]\tvalid_0's mape: 0.0783732\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 0\n",
            "Valid score :  0.07860311911487136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023131 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7709\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 73\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.276547\n",
            "[100]\tvalid_0's mape: 0.0782767\n",
            "[200]\tvalid_0's mape: 0.0732549\n",
            "[300]\tvalid_0's mape: 0.0698422\n",
            "[400]\tvalid_0's mape: 0.0680305\n",
            "[500]\tvalid_0's mape: 0.0668625\n",
            "[600]\tvalid_0's mape: 0.0663172\n",
            "[700]\tvalid_0's mape: 0.0655773\n",
            "[800]\tvalid_0's mape: 0.0649638\n",
            "[900]\tvalid_0's mape: 0.0641687\n",
            "[1000]\tvalid_0's mape: 0.0634411\n",
            "[1100]\tvalid_0's mape: 0.0631317\n",
            "[1200]\tvalid_0's mape: 0.06265\n",
            "[1300]\tvalid_0's mape: 0.0624064\n",
            "[1400]\tvalid_0's mape: 0.0621509\n",
            "[1500]\tvalid_0's mape: 0.0619626\n",
            "[1600]\tvalid_0's mape: 0.0617233\n",
            "[1700]\tvalid_0's mape: 0.0615757\n",
            "[1800]\tvalid_0's mape: 0.0615063\n",
            "[1900]\tvalid_0's mape: 0.0613416\n",
            "[2000]\tvalid_0's mape: 0.0611842\n",
            "[2100]\tvalid_0's mape: 0.06092\n",
            "[2200]\tvalid_0's mape: 0.0608241\n",
            "[2300]\tvalid_0's mape: 0.0606513\n",
            "[2400]\tvalid_0's mape: 0.0605025\n",
            "[2500]\tvalid_0's mape: 0.0603669\n",
            "[2600]\tvalid_0's mape: 0.0602299\n",
            "[2700]\tvalid_0's mape: 0.0601111\n",
            "[2800]\tvalid_0's mape: 0.059989\n",
            "[2900]\tvalid_0's mape: 0.0598888\n",
            "[3000]\tvalid_0's mape: 0.0597974\n",
            "[3100]\tvalid_0's mape: 0.059757\n",
            "[3200]\tvalid_0's mape: 0.0596746\n",
            "[3300]\tvalid_0's mape: 0.05955\n",
            "[3400]\tvalid_0's mape: 0.0595168\n",
            "[3500]\tvalid_0's mape: 0.0594476\n",
            "[3600]\tvalid_0's mape: 0.0593731\n",
            "[3700]\tvalid_0's mape: 0.0593106\n",
            "[3800]\tvalid_0's mape: 0.0592663\n",
            "[3900]\tvalid_0's mape: 0.059204\n",
            "[4000]\tvalid_0's mape: 0.0591745\n",
            "[4100]\tvalid_0's mape: 0.0591568\n",
            "[4200]\tvalid_0's mape: 0.0591186\n",
            "[4300]\tvalid_0's mape: 0.0591029\n",
            "[4400]\tvalid_0's mape: 0.0590792\n",
            "[4500]\tvalid_0's mape: 0.0590726\n",
            "[4600]\tvalid_0's mape: 0.0590472\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 1\n",
            "Valid score :  0.059027537643499314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172555 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8388\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 139\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.059540\n",
            "[100]\tvalid_0's mape: 0.0637756\n",
            "[200]\tvalid_0's mape: 0.0602644\n",
            "[300]\tvalid_0's mape: 0.0584122\n",
            "[400]\tvalid_0's mape: 0.0571102\n",
            "[500]\tvalid_0's mape: 0.0562282\n",
            "[600]\tvalid_0's mape: 0.0554365\n",
            "[700]\tvalid_0's mape: 0.0551432\n",
            "[800]\tvalid_0's mape: 0.0547347\n",
            "[900]\tvalid_0's mape: 0.0544499\n",
            "[1000]\tvalid_0's mape: 0.0540649\n",
            "[1100]\tvalid_0's mape: 0.053798\n",
            "[1200]\tvalid_0's mape: 0.0535505\n",
            "[1300]\tvalid_0's mape: 0.0533578\n",
            "[1400]\tvalid_0's mape: 0.053288\n",
            "[1500]\tvalid_0's mape: 0.053106\n",
            "[1600]\tvalid_0's mape: 0.0530113\n",
            "[1700]\tvalid_0's mape: 0.0528475\n",
            "[1800]\tvalid_0's mape: 0.0527931\n",
            "[1900]\tvalid_0's mape: 0.052753\n",
            "[2000]\tvalid_0's mape: 0.0526562\n",
            "[2100]\tvalid_0's mape: 0.0525967\n",
            "[2200]\tvalid_0's mape: 0.0525489\n",
            "[2300]\tvalid_0's mape: 0.0524918\n",
            "[2400]\tvalid_0's mape: 0.0524633\n",
            "[2500]\tvalid_0's mape: 0.0524207\n",
            "[2600]\tvalid_0's mape: 0.0524051\n",
            "[2700]\tvalid_0's mape: 0.0524154\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 2\n",
            "Valid score :  0.05240070981782317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047237 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8382\n",
            "[LightGBM] [Info] Number of data points in the train set: 74103, number of used features: 139\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 27.913267\n",
            "[100]\tvalid_0's mape: 0.0619732\n",
            "[200]\tvalid_0's mape: 0.0590199\n",
            "[300]\tvalid_0's mape: 0.0566381\n",
            "[400]\tvalid_0's mape: 0.0552742\n",
            "[500]\tvalid_0's mape: 0.0541037\n",
            "[600]\tvalid_0's mape: 0.0535033\n",
            "[700]\tvalid_0's mape: 0.0528276\n",
            "[800]\tvalid_0's mape: 0.0524812\n",
            "[900]\tvalid_0's mape: 0.0520757\n",
            "[1000]\tvalid_0's mape: 0.0518328\n",
            "[1100]\tvalid_0's mape: 0.0515672\n",
            "[1200]\tvalid_0's mape: 0.0513353\n",
            "[1300]\tvalid_0's mape: 0.0511839\n",
            "[1400]\tvalid_0's mape: 0.0511167\n",
            "[1500]\tvalid_0's mape: 0.0510077\n",
            "[1600]\tvalid_0's mape: 0.050886\n",
            "[1700]\tvalid_0's mape: 0.0508193\n",
            "[1800]\tvalid_0's mape: 0.0507022\n",
            "[1900]\tvalid_0's mape: 0.0506464\n",
            "[2000]\tvalid_0's mape: 0.0506304\n",
            "[2100]\tvalid_0's mape: 0.0506068\n",
            "[2200]\tvalid_0's mape: 0.0505248\n",
            "[2300]\tvalid_0's mape: 0.0504606\n",
            "[2400]\tvalid_0's mape: 0.050409\n",
            "[2500]\tvalid_0's mape: 0.0503687\n",
            "[2600]\tvalid_0's mape: 0.0503497\n",
            "[2700]\tvalid_0's mape: 0.0502989\n",
            "[2800]\tvalid_0's mape: 0.0502602\n",
            "[2900]\tvalid_0's mape: 0.0502431\n",
            "[3000]\tvalid_0's mape: 0.0502298\n",
            "[3100]\tvalid_0's mape: 0.0502268\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 3\n",
            "Valid score :  0.050210254469889554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5d20585fe547>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['split'] = 'train'\n",
            "<ipython-input-16-5d20585fe547>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['split'] = 'valid'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052378 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8070\n",
            "[LightGBM] [Info] Number of data points in the train set: 74104, number of used features: 137\n",
            "[LightGBM] [Warning] num_iterations is set=10000, num_boost_round=10000 will be ignored. Current value: num_iterations=10000\n",
            "[LightGBM] [Info] Start training from score 28.131925\n",
            "[100]\tvalid_0's mape: 0.0556199\n",
            "[200]\tvalid_0's mape: 0.0522879\n",
            "[300]\tvalid_0's mape: 0.050776\n",
            "[400]\tvalid_0's mape: 0.0497012\n",
            "[500]\tvalid_0's mape: 0.0491696\n",
            "[600]\tvalid_0's mape: 0.0486215\n",
            "[700]\tvalid_0's mape: 0.048374\n",
            "[800]\tvalid_0's mape: 0.0482215\n",
            "[900]\tvalid_0's mape: 0.0480951\n",
            "[1000]\tvalid_0's mape: 0.0479196\n",
            "[1100]\tvalid_0's mape: 0.0477701\n",
            "[1200]\tvalid_0's mape: 0.0476865\n",
            "[1300]\tvalid_0's mape: 0.0476556\n",
            "[1400]\tvalid_0's mape: 0.0476657\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "Fold : 4\n",
            "Valid score :  0.04763536390946603\n",
            "_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*_-*\n",
            "OOF score :  0.05757550430127282\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "kf = model_selection.KFold(n_splits=5)\n",
        "kf = kf.split(X=train_KPI_merge_KPI_lagging)\n",
        "\n",
        "oof_valid_preds = np.zeros(train_KPI_merge_KPI_lagging.shape[0], )\n",
        "test_preds_list = []\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(kf):\n",
        "\n",
        "    train_df = train_KPI_merge_KPI_lagging.iloc[train_idx]\n",
        "    valid_df = train_KPI_merge_KPI_lagging.iloc[valid_idx]\n",
        "    test_df = test_KPI_merge_KPI_lagging.copy()\n",
        "\n",
        "    train_df, valid_df, test_df, _ = feature_enginning(train_df=train_df, valid_df=valid_df, test_df=test_df)\n",
        "    train_cols = [col for col in train_df.columns if col not in drop_cols]\n",
        "\n",
        "    X_train, y_train = train_df[train_cols], train_df[target_col]\n",
        "    X_valid, y_valid = valid_df[train_cols], valid_df[target_col]\n",
        "    X_test = test_df[train_cols]\n",
        "\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_jobs': -1,\n",
        "        'max_depth' : -1,\n",
        "        'metric': 'mape',\n",
        "        'num_boost_round': 10000,\n",
        "    }\n",
        "\n",
        "    # model = lgb.LGBMRegressor(**lgb_study.best_params)\n",
        "    model2 = lgb.LGBMRegressor(**params)\n",
        "    # model = lgb.LGBMRegressor()\n",
        "\n",
        "    early_stopping_callback = lgb.early_stopping(100, first_metric_only=True, verbose=False)\n",
        "    verbose_callback = lgb.log_evaluation(100)\n",
        "\n",
        "    model2.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        callbacks=[early_stopping_callback, verbose_callback],\n",
        "    )\n",
        "\n",
        "    valid_preds = model2.predict(X_valid)\n",
        "    test_preds = model2.predict(X_test)\n",
        "\n",
        "    val_score = metrics.mean_absolute_percentage_error(y_valid, valid_preds)\n",
        "    oof_valid_preds[valid_idx] = valid_preds\n",
        "    test_preds_list.append(test_preds)\n",
        "\n",
        "    print(\"=*\"*50)\n",
        "    print(f\"Fold : {i}\")\n",
        "    print(f\"Valid score : \", val_score)\n",
        "\n",
        "oof_score = metrics.mean_absolute_percentage_error(train_KPI_merge_KPI_lagging[target_col], oof_valid_preds)\n",
        "print(\"_-*\"*50)\n",
        "print(f\"OOF score : \", oof_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWxE1VMyCiyY"
      },
      "outputs": [],
      "source": [
        "test_preds_mean = np.mean(test_preds_list, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dwt5jpn5LPN"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['ID'] = test_df['time'] + '_' + test_df['bs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-jBg3sw4N0B"
      },
      "outputs": [],
      "source": [
        "submission['Energy'] = test_preds_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWSe5WoW4bxR"
      },
      "outputs": [],
      "source": [
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}